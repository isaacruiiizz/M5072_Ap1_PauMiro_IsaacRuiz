#  Part 1: ETL i Model de Dades

## Introducci贸 i Objectius
En aquesta fase inicial, l'objectiu 茅s transformar les dades "crues" de MongoDB en un dataset estructurat i net, preparat per a l'aprenentatge automtic. Hem realitzat un proc茅s ETL (Extract, Transform, Load) complet.

## 0. Creaci贸 entorn Docker
Per a crear l'entorn Docker, s'ha utilitzat el fitxer `docker-compose.yaml` on s'ha configurat un container de MongoDB. Un cop tenim el container de MongoDB en funcionament, podem connectar-nos a la base de dades i comen莽ar a treballar amb les dades.

## 1. Restaurar dades MongoDB
Copiarem el fitxer de backup de MongoDB que hem fet anteriorment i el guardarem en el directori `tmp` del container de MongoDB.

![alt text](Imagenes/CopiaBackupDocker.png)

Un cop tenim el fitxer de backup en el directori `tmp`, podem restaurar les dades a la base de dades.

![alt text](Imagenes/RestauracioDades.png)

## 2. Connectivitat MongoDB amb Python
Abans de connectar-nos a la base de dades, hem de instal路lar les llibreries necessries. Per fer-ho tot m茅s senzill, hem utilitzat el fitxer `requirements.txt` amb les llibreries que utilitzarem durant el proc茅s.

![alt text](Imagenes/Part1/InstalacioLlibreries.png)

Un cop instal路lades les llibreries, podem connectar-nos a la base de dades i comen莽ar a treballar amb les dades. Per realitzar aix貌 hem utilitzat el fitxer `connMongo.py` on hem creat una funci贸 que retorna la connexi贸 a la base de dades. Un cop tenim aquest fitxer farem una petita prova de connexi贸 al mongoDB.

![alt text](Imagenes/Part1/ProvaConnexio.png)

Com veiem hem mostrat un resultat de FEB3_players_statistics i podem veure que la connexi贸 ha estat correcta.

## 3. Definici贸 de l'Arquitectura de Dades

Per tal d'estructurar el flux de dades de manera professional i escalable, hem decidit implementar una **Arquitectura Medallion (Multi-hop Architecture)** utilitzant **Azure Blob Storage** com a Data Lake.

Aquesta arquitectura organitza les dades en tres capes l貌giques de qualitat progressiva:

### 3.1. Per qu猫 Azure Blob Storage?
Hem decidit externalitzar l'emmagatzematge al n煤vol (Cloud) per diversos motius t猫cnics:

* **Simulaci贸 d'entorn Big Data real:** En la ind煤stria, les dades no es guarden en local, sin贸 en Data Lakes distribu茂ts.
* **Desacoblament (Decoupling):** Separem la *computaci贸* (el nostre script Python local) de l'*emmagatzematge* (Azure). Aix貌 permet que tant l'Isaac com el Pau puguin accedir a les mateixes dades processades sense haver d'enviar-se fitxers CSV manualment.
* **Tra莽abilitat:** Podem mantenir l'hist貌ric de les dades originals encara que ens equivoquem en el processament posterior.

### 3.2. Estructura de Capes (The Medallion Architecture)

El nostre pipeline ETL mou les dades a trav茅s de tres contenidors al n煤vol:

####  Capa BRONZE (Raw Zone)
* **Descripci贸:** s la "zona d'aterratge". Cont茅 una c貌pia exacta de les dades tal com s'han extret de MongoDB, sense cap modificaci贸.
* **Format:** Fitxer `.csv` amb totes les columnes originals.
* **Funci贸:** Actua com a c貌pia de seguretat immutable. Si cometem un error en la neteja, sempre podem tornar a aquesta capa per regenerar el dataset sense haver de tornar a consultar la base de dades.
* **Contingut:** Totes les temporades i competicions (FEB3/EBA) amb registres "bruts" (inclosos jugadors amb 0 minuts, noms duplicats o dades err貌nies).

####  Capa SILVER (Clean Zone)
* **Descripci贸:** Dades netes, filtrades i tipificades.
* **Transformacions aplicades:**
    * **Filtratge de qualitat:** Eliminaci贸 de jugadors amb menys de X minuts o partits jugats (per evitar distorsions estad铆stiques per *small sample size*).
    * **Neteja d'estructures:** Eliminaci贸 de columnes innecessries (IDs interns de Mongo) i estandarditzaci贸 de noms d'equips i temporades.
    * **Gesti贸 de Nuls:** Imputaci贸 de valors `0` on hi ha `NaN` en estad铆stiques de comptatge.
* **Contingut:** Una taula estructurada on cada fila 茅s un jugador/temporada vlid per a l'anlisi.

####  Capa GOLD (Business / ML Zone)
* **Descripci贸:** Dades enriquides i llestes per alimentar el model de Machine Learning.
* **Feature Engineering:** En aquesta capa 茅s on apliquem el coneixement de domini (bsquet) per crear noves m猫triques que no existien a l'origen:
    * **OER (Offensive Efficiency Rating):** Punts per possessi贸.
    * **Possessions Estimades:** F贸rmula avan莽ada per calcular el volum de joc real.
    * **% Volum de Tirs:** Distribuci贸 de tirs (Triples vs Tirs de 2).
* **Contingut final:** Aquest 茅s el dataset (`final_dataset.csv`) que llegir l'algorisme **K-Means** a la Part 2 del projecte.

### 3.3. Esquema del Pipeline

```mermaid
graph LR
    A[("MongoDB (Origen)")] -->|Extract| B(Python Script)
    B -->|Load Raw| C[("Azure Blob: BRONZE")]
    C -->|Clean & Filter| D[("Azure Blob: SILVER")]
    D -->|Feature Engineering| E[("Azure Blob: GOLD")]
    E -->|Input| F{Model K-Means}
    
    style C fill:#cd7f32,stroke:#333,stroke-width:2px,color:white
    style D fill:#c0c0c0,stroke:#333,stroke-width:2px,color:black
    style E fill:#ffd700,stroke:#333,stroke-width:2px,color:black




